---
layout: post
title: "Convergence of Causal Model Under Fairness Constraint"
comments: true
usemathjax: true
---

---

In order to demonstrate the advantage (i.e fast adaptation to new
distribution under fairness constraint) of learning structure based on
correct causal model, under the setting that Y is prediction target, A,
B and C are predictors in which A is sensitive attribute under the
requirement of fairness, we design two structural causal models, model 1
and model 2, which inherit different assumption of causal dependency.
Here we assume model 1 follows the correct causal dependency, model 2
follows one of the incorrect causal dependency.

<p align="center">
  <img src="/assets/post-images/fairness-constraint/model1.png">
  <img src="/assets/post-images/fairness-constraint/model2.png">
  <br/>
  Figure 1: Left: model 1; Right: model 2
</p>

Then we train the two categorical probabilistic models, i.o.w. train
their conditional probability tables, with synthetic categorical data
using gradient-based method to maximize the likelihood$^1$ in two phases
separately:

-   **Phase 1**: Randomly initialize a set of parameters (with respect
    to parameters in Figure 1) as ground truth, use them to generate
    synthetic data, training model 1 and model 2 on generated data,
    using negative likelihood as loss, until convergence. Tracking
    negative log-likelihood on a hold-out test set generated by same
    parameters after every epoch, then compare the convergence speed of
    them.

-   **Phase 2**: Randomly perform intervention on $P(C|Y)$(the four
    parameters above module C in Figure 1) in generated parameters of
    phase 1, then compare the convergence speed through the same
    procedure as phase 1.

In both phases, the fairness of two models are measured in terms of
demographic parity$^2$, which as a term of loss function.

Finally, as an empirical result, it turns out model 1, which is the
model with the correct causal dependency assumption, has following three
merits(Figure 2):

-   In phase 1, faster convergence speed. (1st subfigure)

-   With fairness constraint measured by demographic parity, faster
    converges to a fair state\
    in which demographic parity$\approx0$. (2nd subfigure)

-   In phase 2, faster adaptation speed to new distribution. (3rd subfigure)


<p align="center">
  <img src="/assets/post-images/fairness-constraint/convergence.png">
  <img src="/assets/post-images/fairness-constraint/fair_convergence.png">
  <img src="/assets/post-images/fairness-constraint/transfer_convergence.png">
  <br/>
  Figure 2
</p>

This extends the observations and experimental results in <a href="https://arxiv.org/abs/1901.10912">Yoshua et
al., 2019</a> under fairness setting, and achieved expected results.

------------------------------------------------------------------------
1.Given dataset with size m, defined as $\sum_{i=1}^m logP(a_i, b_i, y_i, c_i)$:<br />
For model 1: $\sum_{i=1}^{m} logP(A=a_i)+logP(B=b_i|A=a_i)+logP(Y=y_i|B=b_i)+logP(C=c_i|Y=y_i)$<br />
For model 2: $\sum_{i=1}^{m} logP(A=a_i)+logP(C=c_i)+logP(Y=y_i|A=a_i,B=b_i)$}<br />
2.Defined as: {$|(P(Y=1|A=0)-P(Y=1|A=1)|$}
